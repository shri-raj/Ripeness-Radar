{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('models/yolov8m-seg.pt')\n",
    "\n",
    "classifier = load_model('models/apple_classifier.h5')\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def preprocess_for_classification(img):\n",
    "    img = cv2.resize(img, (150, 150))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "def classify_apple(apple_img):\n",
    "    processed_img = preprocess_for_classification(apple_img)\n",
    "    preds = classifier.predict(processed_img)\n",
    "    class_idx = np.argmax(preds)\n",
    "    return class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 891.8ms\n",
      "Speed: 22.5ms preprocess, 891.8ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 660.8ms\n",
      "Speed: 7.0ms preprocess, 660.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 629.0ms\n",
      "Speed: 3.0ms preprocess, 629.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 618.9ms\n",
      "Speed: 2.0ms preprocess, 618.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 631.6ms\n",
      "Speed: 3.0ms preprocess, 631.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 620.9ms\n",
      "Speed: 3.0ms preprocess, 620.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 628.5ms\n",
      "Speed: 2.0ms preprocess, 628.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 730.8ms\n",
      "Speed: 5.6ms preprocess, 730.8ms inference, 35.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 658.1ms\n",
      "Speed: 3.5ms preprocess, 658.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 644.6ms\n",
      "Speed: 4.0ms preprocess, 644.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 627.2ms\n",
      "Speed: 4.0ms preprocess, 627.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 644.1ms\n",
      "Speed: 2.0ms preprocess, 644.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 643.3ms\n",
      "Speed: 4.0ms preprocess, 643.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 639.5ms\n",
      "Speed: 3.0ms preprocess, 639.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 654.3ms\n",
      "Speed: 4.0ms preprocess, 654.3ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 951.2ms\n",
      "Speed: 3.0ms preprocess, 951.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 773.1ms\n",
      "Speed: 5.0ms preprocess, 773.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 669.2ms\n",
      "Speed: 2.0ms preprocess, 669.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 631.0ms\n",
      "Speed: 5.0ms preprocess, 631.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 624.8ms\n",
      "Speed: 3.0ms preprocess, 624.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 635.4ms\n",
      "Speed: 2.0ms preprocess, 635.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 699.7ms\n",
      "Speed: 4.5ms preprocess, 699.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 619.3ms\n",
      "Speed: 3.0ms preprocess, 619.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 610.3ms\n",
      "Speed: 3.0ms preprocess, 610.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 615.9ms\n",
      "Speed: 3.0ms preprocess, 615.9ms inference, 18.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 638.2ms\n",
      "Speed: 3.0ms preprocess, 638.2ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tv, 2 cell phones, 630.7ms\n",
      "Speed: 4.0ms preprocess, 630.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 630.3ms\n",
      "Speed: 3.0ms preprocess, 630.3ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 626.9ms\n",
      "Speed: 4.0ms preprocess, 626.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 636.2ms\n",
      "Speed: 3.0ms preprocess, 636.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 631.7ms\n",
      "Speed: 3.0ms preprocess, 631.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 635.1ms\n",
      "Speed: 2.0ms preprocess, 635.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 624.8ms\n",
      "Speed: 2.0ms preprocess, 624.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 654.2ms\n",
      "Speed: 4.6ms preprocess, 654.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 676.5ms\n",
      "Speed: 3.0ms preprocess, 676.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 1 cell phone, 657.5ms\n",
      "Speed: 4.0ms preprocess, 657.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 661.9ms\n",
      "Speed: 3.1ms preprocess, 661.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 670.6ms\n",
      "Speed: 4.0ms preprocess, 670.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 737.3ms\n",
      "Speed: 3.0ms preprocess, 737.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 747.7ms\n",
      "Speed: 4.0ms preprocess, 747.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 sandwich, 733.0ms\n",
      "Speed: 3.0ms preprocess, 733.0ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 715.5ms\n",
      "Speed: 3.0ms preprocess, 715.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 665.8ms\n",
      "Speed: 3.0ms preprocess, 665.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 636.2ms\n",
      "Speed: 3.0ms preprocess, 636.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 631.9ms\n",
      "Speed: 6.0ms preprocess, 631.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 668.8ms\n",
      "Speed: 3.0ms preprocess, 668.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 laptop, 625.7ms\n",
      "Speed: 2.0ms preprocess, 625.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 623.5ms\n",
      "Speed: 3.0ms preprocess, 623.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 636.4ms\n",
      "Speed: 3.0ms preprocess, 636.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 629.0ms\n",
      "Speed: 3.0ms preprocess, 629.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 622.6ms\n",
      "Speed: 2.0ms preprocess, 622.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 635.4ms\n",
      "Speed: 2.0ms preprocess, 635.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 631.9ms\n",
      "Speed: 3.0ms preprocess, 631.9ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 625.2ms\n",
      "Speed: 3.0ms preprocess, 625.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 630.8ms\n",
      "Speed: 3.0ms preprocess, 630.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 634.7ms\n",
      "Speed: 3.1ms preprocess, 634.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 624.1ms\n",
      "Speed: 4.0ms preprocess, 624.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 627.5ms\n",
      "Speed: 3.0ms preprocess, 627.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 623.6ms\n",
      "Speed: 3.0ms preprocess, 623.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 627.6ms\n",
      "Speed: 3.0ms preprocess, 627.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 631.8ms\n",
      "Speed: 2.0ms preprocess, 631.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 623.3ms\n",
      "Speed: 2.0ms preprocess, 623.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 630.4ms\n",
      "Speed: 3.0ms preprocess, 630.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 631.7ms\n",
      "Speed: 2.0ms preprocess, 631.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 626.9ms\n",
      "Speed: 4.0ms preprocess, 626.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 624.8ms\n",
      "Speed: 3.0ms preprocess, 624.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 636.9ms\n",
      "Speed: 2.0ms preprocess, 636.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 651.2ms\n",
      "Speed: 3.0ms preprocess, 651.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 632.6ms\n",
      "Speed: 2.0ms preprocess, 632.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 668.0ms\n",
      "Speed: 2.5ms preprocess, 668.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 631.5ms\n",
      "Speed: 3.0ms preprocess, 631.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 633.8ms\n",
      "Speed: 3.0ms preprocess, 633.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 630.2ms\n",
      "Speed: 4.0ms preprocess, 630.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 632.7ms\n",
      "Speed: 4.0ms preprocess, 632.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 630.8ms\n",
      "Speed: 3.0ms preprocess, 630.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 633.1ms\n",
      "Speed: 3.0ms preprocess, 633.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 627.1ms\n",
      "Speed: 3.0ms preprocess, 627.1ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 641.5ms\n",
      "Speed: 3.6ms preprocess, 641.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 633.3ms\n",
      "Speed: 3.0ms preprocess, 633.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 641.0ms\n",
      "Speed: 2.0ms preprocess, 641.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 630.2ms\n",
      "Speed: 3.0ms preprocess, 630.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 623.7ms\n",
      "Speed: 2.0ms preprocess, 623.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 637.1ms\n",
      "Speed: 3.0ms preprocess, 637.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 627.6ms\n",
      "Speed: 2.0ms preprocess, 627.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 632.8ms\n",
      "Speed: 2.0ms preprocess, 632.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 616.0ms\n",
      "Speed: 3.0ms preprocess, 616.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 625.5ms\n",
      "Speed: 2.5ms preprocess, 625.5ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 637.4ms\n",
      "Speed: 3.0ms preprocess, 637.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 632.9ms\n",
      "Speed: 3.1ms preprocess, 632.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 634.0ms\n",
      "Speed: 3.0ms preprocess, 634.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cup, 633.8ms\n",
      "Speed: 6.0ms preprocess, 633.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 624.7ms\n",
      "Speed: 2.0ms preprocess, 624.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 628.8ms\n",
      "Speed: 3.0ms preprocess, 628.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 670.4ms\n",
      "Speed: 4.0ms preprocess, 670.4ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 627.4ms\n",
      "Speed: 3.0ms preprocess, 627.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 633.0ms\n",
      "Speed: 2.0ms preprocess, 633.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 629.9ms\n",
      "Speed: 2.0ms preprocess, 629.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 626.5ms\n",
      "Speed: 3.5ms preprocess, 626.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 637.2ms\n",
      "Speed: 2.1ms preprocess, 637.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 627.9ms\n",
      "Speed: 4.0ms preprocess, 627.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 630.4ms\n",
      "Speed: 3.0ms preprocess, 630.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 632.9ms\n",
      "Speed: 4.0ms preprocess, 632.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 624.7ms\n",
      "Speed: 2.5ms preprocess, 624.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 618.9ms\n",
      "Speed: 4.0ms preprocess, 618.9ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 630.7ms\n",
      "Speed: 3.0ms preprocess, 630.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 628.5ms\n",
      "Speed: 3.0ms preprocess, 628.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 634.3ms\n",
      "Speed: 2.0ms preprocess, 634.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 632.4ms\n",
      "Speed: 2.0ms preprocess, 632.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 629.9ms\n",
      "Speed: 2.0ms preprocess, 629.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 638.2ms\n",
      "Speed: 2.0ms preprocess, 638.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 636.1ms\n",
      "Speed: 2.0ms preprocess, 636.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 633.0ms\n",
      "Speed: 3.0ms preprocess, 633.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 692.2ms\n",
      "Speed: 3.0ms preprocess, 692.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 673.8ms\n",
      "Speed: 3.0ms preprocess, 673.8ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 1 laptop, 1 cell phone, 715.0ms\n",
      "Speed: 4.6ms preprocess, 715.0ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 671.9ms\n",
      "Speed: 3.0ms preprocess, 671.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 698.2ms\n",
      "Speed: 2.0ms preprocess, 698.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 laptop, 1 cell phone, 701.1ms\n",
      "Speed: 3.0ms preprocess, 701.1ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 765.4ms\n",
      "Speed: 3.0ms preprocess, 765.4ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 728.2ms\n",
      "Speed: 4.0ms preprocess, 728.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 733.6ms\n",
      "Speed: 3.0ms preprocess, 733.6ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 745.7ms\n",
      "Speed: 3.6ms preprocess, 745.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 737.7ms\n",
      "Speed: 4.0ms preprocess, 737.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 728.2ms\n",
      "Speed: 2.0ms preprocess, 728.2ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 703.7ms\n",
      "Speed: 3.0ms preprocess, 703.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 651.6ms\n",
      "Speed: 4.0ms preprocess, 651.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 638.9ms\n",
      "Speed: 4.0ms preprocess, 638.9ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 653.1ms\n",
      "Speed: 2.0ms preprocess, 653.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 651.5ms\n",
      "Speed: 2.0ms preprocess, 651.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 648.2ms\n",
      "Speed: 3.6ms preprocess, 648.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 643.3ms\n",
      "Speed: 3.0ms preprocess, 643.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 669.5ms\n",
      "Speed: 3.5ms preprocess, 669.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 651.8ms\n",
      "Speed: 3.0ms preprocess, 651.8ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 656.0ms\n",
      "Speed: 2.0ms preprocess, 656.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 649.5ms\n",
      "Speed: 6.0ms preprocess, 649.5ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 628.0ms\n",
      "Speed: 3.0ms preprocess, 628.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 621.1ms\n",
      "Speed: 2.0ms preprocess, 621.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 632.9ms\n",
      "Speed: 3.0ms preprocess, 632.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 631.5ms\n",
      "Speed: 3.0ms preprocess, 631.5ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 632.1ms\n",
      "Speed: 3.0ms preprocess, 632.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 651.2ms\n",
      "Speed: 4.0ms preprocess, 651.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 621.7ms\n",
      "Speed: 3.1ms preprocess, 621.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 626.5ms\n",
      "Speed: 2.0ms preprocess, 626.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 1 book, 677.7ms\n",
      "Speed: 3.0ms preprocess, 677.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 637.0ms\n",
      "Speed: 2.0ms preprocess, 637.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 636.3ms\n",
      "Speed: 3.0ms preprocess, 636.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 632.1ms\n",
      "Speed: 3.0ms preprocess, 632.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 629.5ms\n",
      "Speed: 3.0ms preprocess, 629.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 633.9ms\n",
      "Speed: 3.0ms preprocess, 633.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 628.0ms\n",
      "Speed: 3.0ms preprocess, 628.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 626.5ms\n",
      "Speed: 2.0ms preprocess, 626.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 626.2ms\n",
      "Speed: 3.0ms preprocess, 626.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 cell phone, 630.0ms\n",
      "Speed: 2.0ms preprocess, 630.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\n",
      "0: 480x640 3 persons, 4 apples, 641.8ms\n",
      "Speed: 4.0ms preprocess, 641.8ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 3 persons, 5 apples, 673.5ms\n",
      "Speed: 4.0ms preprocess, 673.5ms inference, 13.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      "0: 480x640 3 persons, 6 apples, 637.0ms\n",
      "Speed: 4.0ms preprocess, 637.0ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\n",
      "0: 480x640 2 persons, 4 apples, 639.5ms\n",
      "Speed: 3.0ms preprocess, 639.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 667.3ms\n",
      "Speed: 12.0ms preprocess, 667.3ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 book, 640.9ms\n",
      "Speed: 2.0ms preprocess, 640.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 621.7ms\n",
      "Speed: 3.0ms preprocess, 621.7ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 632.9ms\n",
      "Speed: 3.0ms preprocess, 632.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 645.6ms\n",
      "Speed: 3.0ms preprocess, 645.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 632.9ms\n",
      "Speed: 3.0ms preprocess, 632.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 653.8ms\n",
      "Speed: 3.0ms preprocess, 653.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 649.7ms\n",
      "Speed: 3.0ms preprocess, 649.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 678.4ms\n",
      "Speed: 4.0ms preprocess, 678.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 646.3ms\n",
      "Speed: 2.0ms preprocess, 646.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 625.8ms\n",
      "Speed: 2.0ms preprocess, 625.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 632.7ms\n",
      "Speed: 4.0ms preprocess, 632.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 629.6ms\n",
      "Speed: 3.0ms preprocess, 629.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 639.1ms\n",
      "Speed: 4.1ms preprocess, 639.1ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 636.3ms\n",
      "Speed: 2.0ms preprocess, 636.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 628.0ms\n",
      "Speed: 3.0ms preprocess, 628.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 620.8ms\n",
      "Speed: 2.0ms preprocess, 620.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 633.9ms\n",
      "Speed: 3.0ms preprocess, 633.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 633.4ms\n",
      "Speed: 6.0ms preprocess, 633.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 634.0ms\n",
      "Speed: 2.0ms preprocess, 634.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 625.3ms\n",
      "Speed: 3.0ms preprocess, 625.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 631.0ms\n",
      "Speed: 2.0ms preprocess, 631.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 629.9ms\n",
      "Speed: 3.0ms preprocess, 629.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 633.4ms\n",
      "Speed: 3.0ms preprocess, 633.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 625.5ms\n",
      "Speed: 3.0ms preprocess, 625.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 624.5ms\n",
      "Speed: 3.0ms preprocess, 624.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 laptop, 624.1ms\n",
      "Speed: 2.0ms preprocess, 624.1ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 cell phone, 635.8ms\n",
      "Speed: 3.0ms preprocess, 635.8ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 628.0ms\n",
      "Speed: 3.0ms preprocess, 628.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 669.5ms\n",
      "Speed: 4.0ms preprocess, 669.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 4 persons, 2 apples, 1 laptop, 1 cell phone, 623.1ms\n",
      "Speed: 3.0ms preprocess, 623.1ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "0: 480x640 3 persons, 1 apple, 1 donut, 634.3ms\n",
      "Speed: 4.0ms preprocess, 634.3ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 donut, 627.6ms\n",
      "Speed: 2.0ms preprocess, 627.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 donut, 1 laptop, 630.7ms\n",
      "Speed: 3.0ms preprocess, 630.7ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 donut, 1 laptop, 630.0ms\n",
      "Speed: 2.0ms preprocess, 630.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 donut, 637.4ms\n",
      "Speed: 3.0ms preprocess, 637.4ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 donut, 1 laptop, 633.7ms\n",
      "Speed: 3.0ms preprocess, 633.7ms inference, 9.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 628.8ms\n",
      "Speed: 3.0ms preprocess, 628.8ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 636.5ms\n",
      "Speed: 3.0ms preprocess, 636.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 625.4ms\n",
      "Speed: 2.0ms preprocess, 625.4ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 2 cell phones, 630.2ms\n",
      "Speed: 3.0ms preprocess, 630.2ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 653.4ms\n",
      "Speed: 3.0ms preprocess, 653.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 626.5ms\n",
      "Speed: 2.0ms preprocess, 626.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 apples, 1 laptop, 1 cell phone, 623.6ms\n",
      "Speed: 4.0ms preprocess, 623.6ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 cell phone, 649.5ms\n",
      "Speed: 3.0ms preprocess, 649.5ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 laptop, 642.7ms\n",
      "Speed: 3.0ms preprocess, 642.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\n",
      "0: 480x640 1 person, 2 apples, 1 laptop, 650.4ms\n",
      "Speed: 2.0ms preprocess, 650.4ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "0: 480x640 3 persons, 3 apples, 1 laptop, 1 cell phone, 658.8ms\n",
      "Speed: 2.0ms preprocess, 658.8ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 3 persons, 3 apples, 1 laptop, 1 cell phone, 631.8ms\n",
      "Speed: 3.0ms preprocess, 631.8ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      "0: 480x640 3 persons, 3 apples, 635.9ms\n",
      "Speed: 2.5ms preprocess, 635.9ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "0: 480x640 3 persons, 3 apples, 1 cell phone, 649.1ms\n",
      "Speed: 3.0ms preprocess, 649.1ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "0: 480x640 1 person, 639.0ms\n",
      "Speed: 3.0ms preprocess, 639.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 621.9ms\n",
      "Speed: 4.0ms preprocess, 621.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 623.9ms\n",
      "Speed: 3.0ms preprocess, 623.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 631.2ms\n",
      "Speed: 2.0ms preprocess, 631.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 671.6ms\n",
      "Speed: 4.0ms preprocess, 671.6ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 625.9ms\n",
      "Speed: 5.0ms preprocess, 625.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 633.6ms\n",
      "Speed: 3.0ms preprocess, 633.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 634.7ms\n",
      "Speed: 4.0ms preprocess, 634.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 629.9ms\n",
      "Speed: 3.0ms preprocess, 629.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 632.5ms\n",
      "Speed: 3.0ms preprocess, 632.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 627.4ms\n",
      "Speed: 3.0ms preprocess, 627.4ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 630.1ms\n",
      "Speed: 3.0ms preprocess, 630.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 635.5ms\n",
      "Speed: 2.0ms preprocess, 635.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 book, 624.0ms\n",
      "Speed: 2.0ms preprocess, 624.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 627.0ms\n",
      "Speed: 5.0ms preprocess, 627.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 628.1ms\n",
      "Speed: 2.5ms preprocess, 628.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tv, 627.2ms\n",
      "Speed: 3.0ms preprocess, 627.2ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tv, 625.5ms\n",
      "Speed: 4.0ms preprocess, 625.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tv, 631.5ms\n",
      "Speed: 3.0ms preprocess, 631.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 627.0ms\n",
      "Speed: 3.0ms preprocess, 627.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 626.4ms\n",
      "Speed: 3.4ms preprocess, 626.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 640.2ms\n",
      "Speed: 2.0ms preprocess, 640.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 632.7ms\n",
      "Speed: 3.0ms preprocess, 632.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 628.7ms\n",
      "Speed: 3.0ms preprocess, 628.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 627.5ms\n",
      "Speed: 3.0ms preprocess, 627.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 621.9ms\n",
      "Speed: 2.0ms preprocess, 621.9ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 tv, 1 laptop, 1 cell phone, 624.2ms\n",
      "Speed: 3.0ms preprocess, 624.2ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 tv, 628.0ms\n",
      "Speed: 2.0ms preprocess, 628.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 tv, 1 cell phone, 670.6ms\n",
      "Speed: 4.0ms preprocess, 670.6ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 cell phones, 631.6ms\n",
      "Speed: 3.0ms preprocess, 631.6ms inference, 13.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 639.1ms\n",
      "Speed: 2.0ms preprocess, 639.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 624.1ms\n",
      "Speed: 5.0ms preprocess, 624.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 631.7ms\n",
      "Speed: 2.0ms preprocess, 631.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 628.5ms\n",
      "Speed: 2.0ms preprocess, 628.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 2 cell phones, 625.5ms\n",
      "Speed: 3.0ms preprocess, 625.5ms inference, 10.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 625.8ms\n",
      "Speed: 3.0ms preprocess, 625.8ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 629.7ms\n",
      "Speed: 3.0ms preprocess, 629.7ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 630.1ms\n",
      "Speed: 3.0ms preprocess, 630.1ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 629.8ms\n",
      "Speed: 3.0ms preprocess, 629.8ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 626.6ms\n",
      "Speed: 3.0ms preprocess, 626.6ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 622.6ms\n",
      "Speed: 3.0ms preprocess, 622.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 637.5ms\n",
      "Speed: 3.0ms preprocess, 637.5ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 633.5ms\n",
      "Speed: 5.0ms preprocess, 633.5ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 631.1ms\n",
      "Speed: 4.0ms preprocess, 631.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 621.8ms\n",
      "Speed: 4.0ms preprocess, 621.8ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 623.4ms\n",
      "Speed: 3.0ms preprocess, 623.4ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 624.0ms\n",
      "Speed: 3.0ms preprocess, 624.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 633.7ms\n",
      "Speed: 2.0ms preprocess, 633.7ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 627.8ms\n",
      "Speed: 5.0ms preprocess, 627.8ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 618.4ms\n",
      "Speed: 4.6ms preprocess, 618.4ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 635.4ms\n",
      "Speed: 4.0ms preprocess, 635.4ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 633.9ms\n",
      "Speed: 6.0ms preprocess, 633.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 667.6ms\n",
      "Speed: 3.0ms preprocess, 667.6ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 621.9ms\n",
      "Speed: 3.0ms preprocess, 621.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 636.7ms\n",
      "Speed: 2.0ms preprocess, 636.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 672.3ms\n",
      "Speed: 4.0ms preprocess, 672.3ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 673.2ms\n",
      "Speed: 3.0ms preprocess, 673.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 671.9ms\n",
      "Speed: 4.0ms preprocess, 671.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 677.2ms\n",
      "Speed: 2.0ms preprocess, 677.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 674.6ms\n",
      "Speed: 7.0ms preprocess, 674.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 687.6ms\n",
      "Speed: 3.0ms preprocess, 687.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 tvs, 674.6ms\n",
      "Speed: 4.0ms preprocess, 674.6ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 tv, 697.9ms\n",
      "Speed: 3.0ms preprocess, 697.9ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 680.4ms\n",
      "Speed: 3.1ms preprocess, 680.4ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 679.1ms\n",
      "Speed: 3.0ms preprocess, 679.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 673.5ms\n",
      "Speed: 2.0ms preprocess, 673.5ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 676.4ms\n",
      "Speed: 3.0ms preprocess, 676.4ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 684.1ms\n",
      "Speed: 3.0ms preprocess, 684.1ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 cell phone, 666.2ms\n",
      "Speed: 3.0ms preprocess, 666.2ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 688.9ms\n",
      "Speed: 2.0ms preprocess, 688.9ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 cell phone, 720.1ms\n",
      "Speed: 3.0ms preprocess, 720.1ms inference, 17.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      "0: 480x640 1 person, 3 apples, 1 laptop, 1 cell phone, 746.6ms\n",
      "Speed: 3.0ms preprocess, 746.6ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\n",
      "0: 480x640 2 persons, 2 apples, 1 cell phone, 751.2ms\n",
      "Speed: 2.7ms preprocess, 751.2ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 cell phone, 692.6ms\n",
      "Speed: 4.0ms preprocess, 692.6ms inference, 16.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 cell phone, 710.2ms\n",
      "Speed: 3.0ms preprocess, 710.2ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 1 person, 3 apples, 1 laptop, 1 cell phone, 751.8ms\n",
      "Speed: 4.0ms preprocess, 751.8ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      "0: 480x640 1 person, 3 apples, 1 laptop, 1 cell phone, 829.1ms\n",
      "Speed: 2.0ms preprocess, 829.1ms inference, 16.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\n",
      "0: 480x640 1 person, 3 apples, 1 laptop, 1 cell phone, 818.1ms\n",
      "Speed: 4.0ms preprocess, 818.1ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\n",
      "0: 480x640 2 persons, 3 apples, 1 laptop, 850.3ms\n",
      "Speed: 3.0ms preprocess, 850.3ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 2 oranges, 1 laptop, 834.6ms\n",
      "Speed: 5.0ms preprocess, 834.6ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\n",
      "0: 480x640 2 apples, 2 oranges, 1 tv, 1 laptop, 803.9ms\n",
      "Speed: 4.0ms preprocess, 803.9ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\n",
      "0: 480x640 3 persons, 778.6ms\n",
      "Speed: 4.0ms preprocess, 778.6ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 800.7ms\n",
      "Speed: 5.0ms preprocess, 800.7ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 798.7ms\n",
      "Speed: 3.0ms preprocess, 798.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 796.3ms\n",
      "Speed: 7.0ms preprocess, 796.3ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 1 remote, 794.1ms\n",
      "Speed: 4.5ms preprocess, 794.1ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 1 cell phone, 812.0ms\n",
      "Speed: 3.0ms preprocess, 812.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 1 cell phone, 875.5ms\n",
      "Speed: 4.0ms preprocess, 875.5ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 1 cell phone, 812.3ms\n",
      "Speed: 4.0ms preprocess, 812.3ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 1 cell phone, 812.7ms\n",
      "Speed: 2.0ms preprocess, 812.7ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 bottle, 1 remote, 777.7ms\n",
      "Speed: 4.0ms preprocess, 777.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 737.5ms\n",
      "Speed: 4.6ms preprocess, 737.5ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 remote, 780.6ms\n",
      "Speed: 4.0ms preprocess, 780.6ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 bottle, 762.1ms\n",
      "Speed: 7.0ms preprocess, 762.1ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 remote, 744.7ms\n",
      "Speed: 3.0ms preprocess, 744.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 remote, 745.8ms\n",
      "Speed: 3.0ms preprocess, 745.8ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 689.2ms\n",
      "Speed: 3.0ms preprocess, 689.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 1 laptop, 738.6ms\n",
      "Speed: 3.9ms preprocess, 738.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 2 cell phones, 706.2ms\n",
      "Speed: 3.0ms preprocess, 706.2ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 remote, 1 book, 695.6ms\n",
      "Speed: 3.0ms preprocess, 695.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 remote, 726.4ms\n",
      "Speed: 4.0ms preprocess, 726.4ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 736.5ms\n",
      "Speed: 3.0ms preprocess, 736.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 762.1ms\n",
      "Speed: 4.0ms preprocess, 762.1ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 681.3ms\n",
      "Speed: 3.0ms preprocess, 681.3ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 apples, 1 cell phone, 747.0ms\n",
      "Speed: 3.0ms preprocess, 747.0ms inference, 16.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\n",
      "0: 480x640 3 persons, 2 apples, 711.6ms\n",
      "Speed: 3.0ms preprocess, 711.6ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      "0: 480x640 3 persons, 2 apples, 698.9ms\n",
      "Speed: 4.0ms preprocess, 698.9ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\n",
      "0: 480x640 3 persons, 2 apples, 1 cell phone, 728.8ms\n",
      "Speed: 5.0ms preprocess, 728.8ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 743.1ms\n",
      "Speed: 4.0ms preprocess, 743.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 684.8ms\n",
      "Speed: 3.0ms preprocess, 684.8ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 2 cell phones, 708.0ms\n",
      "Speed: 3.0ms preprocess, 708.0ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 1 cell phone, 668.4ms\n",
      "Speed: 3.0ms preprocess, 668.4ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 2 cell phones, 678.7ms\n",
      "Speed: 4.0ms preprocess, 678.7ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 cell phone, 676.6ms\n",
      "Speed: 2.0ms preprocess, 676.6ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 1 cell phone, 691.4ms\n",
      "Speed: 4.0ms preprocess, 691.4ms inference, 13.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 1 cell phone, 724.6ms\n",
      "Speed: 4.0ms preprocess, 724.6ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 1 cell phone, 686.4ms\n",
      "Speed: 4.0ms preprocess, 686.4ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 cell phone, 684.5ms\n",
      "Speed: 2.0ms preprocess, 684.5ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 2 cell phones, 715.0ms\n",
      "Speed: 3.0ms preprocess, 715.0ms inference, 13.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 1 cell phone, 718.9ms\n",
      "Speed: 3.0ms preprocess, 718.9ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 1 cell phone, 729.4ms\n",
      "Speed: 4.0ms preprocess, 729.4ms inference, 14.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 2 cell phones, 793.0ms\n",
      "Speed: 3.0ms preprocess, 793.0ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 1 cell phone, 732.0ms\n",
      "Speed: 5.6ms preprocess, 732.0ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 2 cell phones, 658.6ms\n",
      "Speed: 2.0ms preprocess, 658.6ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 666.6ms\n",
      "Speed: 2.0ms preprocess, 666.6ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 657.0ms\n",
      "Speed: 4.0ms preprocess, 657.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 646.7ms\n",
      "Speed: 4.0ms preprocess, 646.7ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 664.1ms\n",
      "Speed: 3.0ms preprocess, 664.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 673.7ms\n",
      "Speed: 3.0ms preprocess, 673.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 cell phone, 658.3ms\n",
      "Speed: 3.0ms preprocess, 658.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 cell phone, 653.7ms\n",
      "Speed: 3.0ms preprocess, 653.7ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 1 cell phone, 661.4ms\n",
      "Speed: 3.0ms preprocess, 661.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cell phone, 653.6ms\n",
      "Speed: 3.0ms preprocess, 653.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 654.1ms\n",
      "Speed: 4.0ms preprocess, 654.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 659.1ms\n",
      "Speed: 3.0ms preprocess, 659.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cell phone, 657.7ms\n",
      "Speed: 3.0ms preprocess, 657.7ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 640.0ms\n",
      "Speed: 2.0ms preprocess, 640.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cell phone, 628.2ms\n",
      "Speed: 3.0ms preprocess, 628.2ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cell phone, 632.9ms\n",
      "Speed: 3.0ms preprocess, 632.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cell phone, 631.2ms\n",
      "Speed: 3.0ms preprocess, 631.2ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 653.5ms\n",
      "Speed: 2.0ms preprocess, 653.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 apple, 1 donut, 1 cell phone, 662.7ms\n",
      "Speed: 3.0ms preprocess, 662.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 639.2ms\n",
      "Speed: 4.0ms preprocess, 639.2ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 cell phone, 628.9ms\n",
      "Speed: 2.0ms preprocess, 628.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 cell phone, 634.6ms\n",
      "Speed: 3.0ms preprocess, 634.6ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 662.8ms\n",
      "Speed: 3.0ms preprocess, 662.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 627.8ms\n",
      "Speed: 3.0ms preprocess, 627.8ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 665.8ms\n",
      "Speed: 3.0ms preprocess, 665.8ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 625.1ms\n",
      "Speed: 3.0ms preprocess, 625.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 622.2ms\n",
      "Speed: 3.0ms preprocess, 622.2ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 632.0ms\n",
      "Speed: 3.0ms preprocess, 632.0ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 647.7ms\n",
      "Speed: 3.0ms preprocess, 647.7ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 625.9ms\n",
      "Speed: 3.0ms preprocess, 625.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 630.3ms\n",
      "Speed: 2.0ms preprocess, 630.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 639.8ms\n",
      "Speed: 3.0ms preprocess, 639.8ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 678.1ms\n",
      "Speed: 3.0ms preprocess, 678.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 685.0ms\n",
      "Speed: 4.0ms preprocess, 685.0ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 656.8ms\n",
      "Speed: 3.0ms preprocess, 656.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 657.1ms\n",
      "Speed: 2.5ms preprocess, 657.1ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            class_id = int(box.cls)\n",
    "            if class_id == 47:  \n",
    "                x1, y1, x2, y2 = box.xyxy[0].int()\n",
    "                apple_img = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "\n",
    "                if apple_img.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                apple_class = classify_apple(apple_img)\n",
    "\n",
    "                class_labels = {0: \"Ripe\", 1: \"Rotten\", 2: \"Unripe\"}\n",
    "                label = class_labels.get(apple_class, \"Unknown\")\n",
    "                \n",
    "                red = green = 256\n",
    "                if label == \"Ripe\":\n",
    "                    red = 0\n",
    "                elif label == \"Rotten\":\n",
    "                    green = 0\n",
    "                \n",
    "                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, green, red), 2)\n",
    "                cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, green, red), 2)\n",
    "\n",
    "    cv2.imshow('Live Apple Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
